<div align="center">

# ğŸ§  The Machine Learning Workbench

### **Version 3.6 â€” The Complete Selection Suite**

*The Definitive ML Educational Platform: Three Philosophies of Feature Selection*

---

![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.3+-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Statsmodels](https://img.shields.io/badge/Statsmodels-0.14+-4051B5?style=for-the-badge&logo=python&logoColor=white)
![Plotly](https://img.shields.io/badge/Plotly-5.18+-3F4F75?style=for-the-badge&logo=plotly&logoColor=white)
![Version](https://img.shields.io/badge/Version-3.6-blueviolet?style=for-the-badge)
![Modules](https://img.shields.io/badge/Modules-7-orange?style=for-the-badge)
![Selection Methods](https://img.shields.io/badge/Selection_Methods-3-success?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

<br>

[**Features**](#-key-features) Â· [**Modules**](#-module-overview) Â· [**Installation**](#-installation) Â· [**User Guide**](#-user-guide)

<br>

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                               â•‘
â•‘   "Three paths to feature selection: Statistical elimination, performance    â•‘
â•‘    recruitment, or mathematical shrinkage. All roads lead to simplicity."    â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [What's New in v3.6](#-whats-new-in-v36)
- [Key Features](#-key-features)
- [Module Overview](#-module-overview)
- [Module G: Feature Selection Suite (Complete)](#-module-g-feature-selection-suite-complete)
- [Tech Stack](#-tech-stack)
- [Installation](#-installation)
- [User Guide](#-user-guide)
- [Disclaimer](#-disclaimer)
- [Author](#-author)

---

## ğŸš€ Overview

**The Machine Learning Workbench v3.6** delivers the **complete ML educational platform** â€” a comprehensive learning environment spanning from fundamental algorithms to advanced feature engineering with three distinct selection methodologies.

This release completes the Feature Selection Suite by adding **LASSO (L1 Regularization)**, offering users a third powerful approach to identifying the features that truly matter.

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   THREE PHILOSOPHIES OF FEATURE SELECTION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚    ğŸ”™ BACKWARD              ğŸ”œ FORWARD               ğŸ¯ LASSO                   â”‚
â”‚    ELIMINATION              SELECTION               REGULARIZATION              â”‚
â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚                                                                                 â”‚
â”‚    "The Garbage             "The Talent             "The Shrink                 â”‚
â”‚     Collector"               Scout"                  Ray"                       â”‚
â”‚                                                                                 â”‚
â”‚    Start: ALL               Start: ZERO             Start: ALL                  â”‚
â”‚    Action: REMOVE           Action: ADD             Action: SHRINK              â”‚
â”‚    Metric: P-Value          Metric: RÂ²              Metric: Coefficient         â”‚
â”‚    Tool: Statsmodels        Tool: Sklearn           Tool: Sklearn.Lasso         â”‚
â”‚                                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚    â”‚â–ˆâ–ˆ â–ˆâ–ˆ â–ˆâ–ˆ â–ˆâ–ˆâ”‚            â”‚           â”‚           â”‚â–ˆâ–ˆ â–ˆâ–ˆ â–ˆâ–ˆ â–ˆâ–ˆâ”‚               â”‚
â”‚    â”‚â–ˆâ–ˆ â–ˆâ–ˆ â–ˆâ–ˆ   â”‚            â”‚        â–ˆâ–ˆ â”‚           â”‚â–ˆâ–ˆ â–ªâ–ª â–ªâ–ª â–ˆâ–ˆâ”‚               â”‚
â”‚    â”‚â–ˆâ–ˆ â–ˆâ–ˆ      â”‚ â”€â”€â”€â–º       â”‚     â–ˆâ–ˆ â–ˆâ–ˆ â”‚ â”€â”€â”€â–º      â”‚â–ˆâ–ˆ    Â·  â–ˆâ–ˆâ”‚ â”€â”€â”€â–º          â”‚
â”‚    â”‚â–ˆâ–ˆ         â”‚            â”‚  â–ˆâ–ˆ â–ˆâ–ˆ â–ˆâ–ˆ â”‚           â”‚â–ˆâ–ˆ       â–ˆâ–ˆâ”‚               â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚     Subtractive              Additive               Shrinkage                   â”‚
â”‚                                                     (to zero)                   â”‚
â”‚                                                                                 â”‚
â”‚    SAME DESTINATION: The optimal, minimal feature set                           â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

### Platform Capabilities

| Capability | Description | Module |
|------------|-------------|--------|
| ğŸ“ˆ **Visualization** | See algorithms think in real-time | A, B, C |
| âš”ï¸ **Comparison** | Pit algorithms against each other | D |
| ğŸ”¬ **Validation** | Test reliability with K-Fold CV | E |
| ğŸ” **Optimization** | Auto-tune hyperparameters | F |
| ğŸ¯ **Feature Selection** | Three methods: Backward, Forward, **LASSO** | G |

---

## âœ¨ What's New in v3.6

### ğŸ¯ LASSO Regularization â€” "The Shrink Ray"

The Feature Selection Suite is now **complete** with three distinct methodologies:

<div align="center">

| Tab | Method | Metaphor | Mechanism | Library |
|:---:|:-------|:---------|:----------|:--------|
| ğŸ”™ **Tab 1** | Backward Elimination | The Garbage Collector | Remove by P-Value | Statsmodels |
| ğŸ”œ **Tab 2** | Forward Selection | The Talent Scout | Add by RÂ² gain | Scikit-Learn |
| ğŸ¯ **Tab 3** | **LASSO (L1)** | **The Shrink Ray** | **Shrink to Zero** | **Scikit-Learn** |

</div>

### What Makes LASSO Different?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LASSO: THE MATHEMATICAL APPROACH                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  BACKWARD & FORWARD:                    LASSO:                                  â”‚
â”‚  Binary decisions                       Continuous shrinkage                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚
â”‚                                                                                 â”‚
â”‚  Feature is either:                     Feature coefficients:                   â”‚
â”‚    âœ… IN the model                        ğŸ“Š Gradually shrink                   â”‚
â”‚    âŒ OUT of the model                    ğŸ“‰ Until they hit ZERO                â”‚
â”‚                                           ğŸ¯ Then effectively removed           â”‚
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                                         â”‚    â”‚
â”‚  â”‚   THE SHRINKAGE EFFECT (as Alpha increases):                           â”‚    â”‚
â”‚  â”‚                                                                         â”‚    â”‚
â”‚  â”‚   Alpha = 0.01        Alpha = 0.10        Alpha = 1.00                  â”‚    â”‚
â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚    â”‚
â”‚  â”‚                                                                         â”‚    â”‚
â”‚  â”‚   Study_Hours: 8.72   Study_Hours: 8.45   Study_Hours: 7.89            â”‚    â”‚
â”‚  â”‚   Shoe_Size:   0.23   Shoe_Size:   0.08   Shoe_Size:   0.00 â† GONE!    â”‚    â”‚
â”‚  â”‚   Jersey_Num: -0.12   Jersey_Num:  0.00   Jersey_Num:  0.00 â† GONE!    â”‚    â”‚
â”‚  â”‚   Fav_Color:   0.15   Fav_Color:   0.02   Fav_Color:   0.00 â† GONE!    â”‚    â”‚
â”‚  â”‚                                                                         â”‚    â”‚
â”‚  â”‚   Noise coefficients PHYSICALLY SHRINK TO ZERO                          â”‚    â”‚
â”‚  â”‚                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Alpha Slider

LASSO introduces an interactive **Alpha (Î±) slider** that controls regularization strength:

| Alpha Value | Effect | Interpretation |
|-------------|--------|----------------|
| **Î± â†’ 0** | Minimal penalty | Behaves like standard regression |
| **Î± = 0.1** | Moderate penalty | Weak features start shrinking |
| **Î± = 1.0** | Strong penalty | Only strongest features survive |
| **Î± â†’ âˆ** | Maximum penalty | All coefficients â†’ 0 |

---

## ğŸ¯ Key Features

<table>
<tr>
<td width="50%">

### ğŸ“ˆ Core Algorithms
- **Linear Regression** â€” Continuous prediction
- **Logistic Regression** â€” Binary classification
- **Decision Trees** â€” Non-linear boundaries
- **Real-time Training** â€” Instant visual feedback

</td>
<td width="50%">

### ğŸ”¬ Validation & Reliability
- **K-Fold Cross-Validation** â€” Multi-split testing
- **Variance Analysis** â€” Stability metrics
- **Per-Fold Breakdown** â€” Granular insights

</td>
</tr>
<tr>
<td width="50%">

### ğŸ” Automation & Tuning
- **Grid Search** â€” Exhaustive parameter sweep
- **Heatmap Visualization** â€” Parameter landscapes
- **Best Config Discovery** â€” Automatic optimization

</td>
<td width="50%">

### ğŸ¯ Feature Selection Suite (COMPLETE)
- ğŸ”™ **Backward Elimination** â€” P-Value pruning
- ğŸ”œ **Forward Selection** â€” RÂ² recruitment
- ğŸ¯ **LASSO (L1)** â€” Coefficient shrinkage
- **Interactive Alpha Control** â€” Real-time regularization

</td>
</tr>
</table>

---

## ğŸ“¦ Module Overview

The Workbench contains **7 distinct learning modules** with a now-complete Feature Selection Suite:

<div align="center">

| Module | Name | Icon | Focus Area | Key Concept |
|:------:|:-----|:----:|:-----------|:------------|
| **A** | Linear Regression | ğŸ“ˆ | Continuous Prediction | OLS, Best-Fit Line |
| **B** | Logistic Regression | ğŸ“Š | Binary Classification | Sigmoid, Probability |
| **C** | Decision Tree | ğŸŒ³ | Non-linear Boundaries | Gini Impurity, Splits |
| **D** | Model Showdown | âš”ï¸ | Algorithm Comparison | Linear vs Non-linear |
| **E** | Cross-Validation Lab | ğŸ”¬ | Reliability Testing | K-Fold, Variance |
| **F** | Grid Search Lab | ğŸ” | Hyperparameter Tuning | Exhaustive Search |
| **G** | **Feature Selection Suite** | ğŸ¯ | **Feature Engineering** | **3 Methods Complete** |

</div>

### Module G: Three Selection Strategies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODULE G: FEATURE SELECTION SUITE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚ ğŸ”™ Tab 1          â”‚ ğŸ”œ Tab 2          â”‚ ğŸ¯ Tab 3          â”‚                 â”‚
â”‚   â”‚ BACKWARD          â”‚ FORWARD           â”‚ LASSO             â”‚                 â”‚
â”‚   â”‚ ELIMINATION       â”‚ SELECTION         â”‚ (L1 Regularization)â”‚                â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚   â”‚                   â”‚                   â”‚                   â”‚                 â”‚
â”‚   â”‚ P-Value Based     â”‚ RÂ² Based          â”‚ Penalty Based     â”‚                 â”‚
â”‚   â”‚ Statsmodels       â”‚ Scikit-Learn      â”‚ Scikit-Learn      â”‚                 â”‚
â”‚   â”‚ Discrete removal  â”‚ Discrete addition â”‚ Continuous shrink â”‚                 â”‚
â”‚   â”‚                   â”‚                   â”‚                   â”‚                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Module G: Feature Selection Suite (Complete)

<div align="center">

### **Three Tabs. Three Philosophies. One Goal.**

*The complete toolkit for identifying features that matter*

</div>

---

### ğŸ”™ Tab 1: Backward Elimination â€” "The Garbage Collector"

**Philosophy:** Start with everything, remove the statistically insignificant.

| Aspect | Detail |
|--------|--------|
| **Starting Point** | All features included |
| **Metric** | P-Value (statistical significance) |
| **Threshold** | P > 0.05 â†’ Remove |
| **Library** | `statsmodels.OLS` |
| **Output** | Elimination Log + P-Value Chart |

```python
import statsmodels.api as sm

# Iteratively remove features with P > 0.05
model = sm.OLS(y, sm.add_constant(X)).fit()
p_values = model.pvalues
```

---

### ğŸ”œ Tab 2: Forward Selection â€” "The Talent Scout"

**Philosophy:** Start with nothing, recruit only features that improve performance.

| Aspect | Detail |
|--------|--------|
| **Starting Point** | Zero features (empty model) |
| **Metric** | RÂ² (variance explained) |
| **Criterion** | Add feature with max RÂ² improvement |
| **Library** | `sklearn.linear_model.LinearRegression` |
| **Output** | RÂ² Growth Chart |

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Iteratively add features that maximize RÂ²
model = LinearRegression().fit(X[selected], y)
r2 = r2_score(y, model.predict(X[selected]))
```

---

### ğŸ¯ Tab 3: LASSO (L1 Regularization) â€” "The Shrink Ray" (NEW!)

**Philosophy:** Let mathematics naturally shrink useless coefficients to exactly zero.

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸ¯ LASSO REGULARIZATION                                  â”‚
â”‚                        "The Shrink Ray"                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  THE CONCEPT:                                                                   â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•                                                                   â”‚
â”‚  LASSO adds a PENALTY term to the loss function that punishes large            â”‚
â”‚  coefficients. Noise features, which have weak relationships with the          â”‚
â”‚  target, cannot "afford" the penalty and shrink to EXACTLY ZERO.               â”‚
â”‚                                                                                 â”‚
â”‚  LOSS FUNCTION:                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                                         â”‚    â”‚
â”‚  â”‚   Standard OLS:   minimize  Î£(yáµ¢ - Å·áµ¢)Â²                                 â”‚    â”‚
â”‚  â”‚                                                                         â”‚    â”‚
â”‚  â”‚   LASSO (L1):     minimize  Î£(yáµ¢ - Å·áµ¢)Â²  +  Î± Ã— Î£|Î²â±¼|                   â”‚    â”‚
â”‚  â”‚                             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚    â”‚
â”‚  â”‚                              Prediction       L1 Penalty                â”‚    â”‚
â”‚  â”‚                                Error          (shrinkage)               â”‚    â”‚
â”‚  â”‚                                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                 â”‚
â”‚  THE ALPHA (Î±) SLIDER:                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                          â”‚
â”‚                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚  Alpha:  [0.01]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[10.0]  â”‚       â”‚
â”‚   â”‚                            â–²                                        â”‚       â”‚
â”‚   â”‚                       Current: 0.50                                 â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                                 â”‚
â”‚   Î± â†’ 0:    Minimal penalty â†’ All features kept (like OLS)                      â”‚
â”‚   Î± â†‘:      Increasing penalty â†’ Weak features start shrinking                  â”‚
â”‚   Î± â†’ âˆ:    Maximum penalty â†’ All coefficients â†’ 0                              â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

#### How LASSO Shrinks Coefficients

As you increase the Alpha slider, watch what happens to the coefficients:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COEFFICIENT EVOLUTION AS ALPHA INCREASES                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  Feature          â”‚ Î±=0.01  â”‚ Î±=0.05  â”‚ Î±=0.10  â”‚ Î±=0.50  â”‚ Î±=1.00  â”‚ Status   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  Study_Hours      â”‚  8.723  â”‚  8.698  â”‚  8.651  â”‚  8.234  â”‚  7.891  â”‚ âœ… KEPT  â”‚
â”‚  Shoe_Size        â”‚  0.234  â”‚  0.156  â”‚  0.087  â”‚  0.012  â”‚  0.000  â”‚ âŒ GONE  â”‚
â”‚  Jersey_Number    â”‚ -0.123  â”‚ -0.067  â”‚ -0.021  â”‚  0.000  â”‚  0.000  â”‚ âŒ GONE  â”‚
â”‚  Favorite_Color   â”‚  0.156  â”‚  0.098  â”‚  0.034  â”‚  0.000  â”‚  0.000  â”‚ âŒ GONE  â”‚
â”‚                                                                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                                 â”‚
â”‚  INTERPRETATION:                                                                â”‚
â”‚  â€¢ Study_Hours maintains a strong coefficient â†’ REAL SIGNAL                     â”‚
â”‚  â€¢ Noise features progressively shrink â†’ eventually hit EXACTLY 0.000           â”‚
â”‚  â€¢ Zero coefficient = Feature mathematically removed from equation              â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### The Coefficient Bar Chart

The LASSO tab features a powerful **Coefficient Bar Chart** visualization:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ğŸ“Š COEFFICIENT BAR CHART                                   â”‚
â”‚                      (Alpha = 0.50)                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  Coefficient                                                                    â”‚
â”‚  Value                                                                          â”‚
â”‚    â”‚                                                                            â”‚
â”‚    â”‚                                                                            â”‚
â”‚  8 â”¤   â”Œâ”€â”€â”€â”€â”€â”€â”€â”                                                                â”‚
â”‚    â”‚   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                                                                â”‚
â”‚    â”‚   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                                                                â”‚
â”‚  6 â”¤   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                                                                â”‚
â”‚    â”‚   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ â† GREEN: Strong positive coefficient                          â”‚
â”‚    â”‚   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚          (Study_Hours = 8.23)                                  â”‚
â”‚  4 â”¤   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                                                                â”‚
â”‚    â”‚   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                                                                â”‚
â”‚    â”‚   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                                                                â”‚
â”‚  2 â”¤   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                                                                â”‚
â”‚    â”‚   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                                                                â”‚
â”‚    â”‚   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                                                                â”‚
â”‚  0 â”¼â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚    â”‚                â”‚            â”‚            â”‚            â”‚                    â”‚
â”‚    â”‚               â”Œâ”´â”          â”Œâ”´â”          â”Œâ”´â”                                â”‚
â”‚    â”‚               â”‚â–“â”‚          â”‚â–“â”‚          â”‚â–“â”‚                                â”‚
â”‚    â”‚               â””â”€â”˜          â””â”€â”˜          â””â”€â”˜                                â”‚
â”‚    â”‚                                                                            â”‚
â”‚    â”‚             â† RED: Coefficient = 0.00 (ELIMINATED)                         â”‚
â”‚    â”‚                                                                            â”‚
â”‚       Study      Shoe        Jersey      Favorite                               â”‚
â”‚       Hours      Size        Number       Color                                 â”‚
â”‚                                                                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                                 â”‚
â”‚  LEGEND:                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ğŸŸ© GREEN BAR  = Active feature (coefficient â‰  0)                        â”‚   â”‚
â”‚  â”‚  ğŸŸ¥ RED BAR    = Eliminated feature (coefficient = 0.00)                 â”‚   â”‚
â”‚  â”‚  BAR HEIGHT   = Magnitude of coefficient                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### LASSO Implementation

```python
from sklearn.linear_model import Lasso

def lasso_selection(X, y, alpha=1.0):
    """
    Perform LASSO feature selection via L1 regularization.
    
    Parameters:
    -----------
    X : DataFrame
        Feature matrix
    y : Series
        Target variable
    alpha : float
        Regularization strength (higher = more shrinkage)
    
    Returns:
    --------
    dict : Feature coefficients (zeros indicate elimination)
    """
    # Fit LASSO model
    lasso = Lasso(alpha=alpha, random_state=42)
    lasso.fit(X, y)
    
    # Extract coefficients
    coefficients = dict(zip(X.columns, lasso.coef_))
    
    # Identify eliminated features (coefficient = 0)
    eliminated = [f for f, c in coefficients.items() if c == 0]
    selected = [f for f, c in coefficients.items() if c != 0]
    
    return {
        'coefficients': coefficients,
        'selected': selected,
        'eliminated': eliminated
    }

# Example usage
result = lasso_selection(X, y, alpha=0.5)
print(f"Selected: {result['selected']}")
print(f"Eliminated: {result['eliminated']}")
```

---

### ğŸ”„ Three Methods Compared

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPLETE COMPARISON: ALL THREE METHODS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚                         â”‚                         â”‚
â”‚  ğŸ”™ BACKWARD ELIMINATION    â”‚  ğŸ”œ FORWARD SELECTION   â”‚  ğŸ¯ LASSO (L1)          â”‚
â”‚                             â”‚                         â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚                         â”‚                         â”‚
â”‚  Metaphor:                  â”‚  Metaphor:              â”‚  Metaphor:              â”‚
â”‚  "The Garbage Collector"    â”‚  "The Talent Scout"     â”‚  "The Shrink Ray"       â”‚
â”‚                             â”‚                         â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚                         â”‚                         â”‚
â”‚  Starting Point:            â”‚  Starting Point:        â”‚  Starting Point:        â”‚
â”‚  ALL features               â”‚  ZERO features          â”‚  ALL features           â”‚
â”‚                             â”‚                         â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚                         â”‚                         â”‚
â”‚  Action:                    â”‚  Action:                â”‚  Action:                â”‚
â”‚  REMOVE worst               â”‚  ADD best               â”‚  SHRINK to zero         â”‚
â”‚                             â”‚                         â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚                         â”‚                         â”‚
â”‚  Selection Type:            â”‚  Selection Type:        â”‚  Selection Type:        â”‚
â”‚  Discrete (in/out)          â”‚  Discrete (in/out)      â”‚  Continuous (shrinkage) â”‚
â”‚                             â”‚                         â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚                         â”‚                         â”‚
â”‚  Metric:                    â”‚  Metric:                â”‚  Metric:                â”‚
â”‚  P-Value                    â”‚  RÂ² Score               â”‚  Coefficient magnitude  â”‚
â”‚                             â”‚                         â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚                         â”‚                         â”‚
â”‚  Threshold:                 â”‚  Threshold:             â”‚  Control:               â”‚
â”‚  P > 0.05                   â”‚  Î”RÂ² < threshold        â”‚  Alpha (Î±) slider       â”‚
â”‚                             â”‚                         â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚                         â”‚                         â”‚
â”‚  Library:                   â”‚  Library:               â”‚  Library:               â”‚
â”‚  statsmodels.OLS            â”‚  sklearn.LinearReg      â”‚  sklearn.Lasso          â”‚
â”‚                             â”‚                         â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚                         â”‚                         â”‚
â”‚  Output:                    â”‚  Output:                â”‚  Output:                â”‚
â”‚  â€¢ Elimination Log          â”‚  â€¢ RÂ² Growth Chart      â”‚  â€¢ Coefficient Bar Chartâ”‚
â”‚  â€¢ P-Value Chart            â”‚  â€¢ Feature Rankings     â”‚  â€¢ Zero = Eliminated    â”‚
â”‚                             â”‚                         â”‚  â€¢ Red bars = removed   â”‚
â”‚                             â”‚                         â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚                         â”‚                         â”‚
â”‚  Best When:                 â”‚  Best When:             â”‚  Best When:             â”‚
â”‚  â€¢ Need inference           â”‚  â€¢ Need interpretable   â”‚  â€¢ Many features        â”‚
â”‚  â€¢ Small feature sets       â”‚    performance gains    â”‚  â€¢ Want automatic       â”‚
â”‚  â€¢ Statistical rigor        â”‚  â€¢ Most features        â”‚    selection            â”‚
â”‚    required                 â”‚    likely useless       â”‚  â€¢ Continuous control   â”‚
â”‚                             â”‚                         â”‚    desired              â”‚
â”‚                             â”‚                         â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

### When to Use Each Method

| Scenario | Recommended Method | Reason |
|----------|-------------------|--------|
| Need statistical significance | ğŸ”™ Backward | P-Values provide inference |
| Building from scratch | ğŸ”œ Forward | See incremental gains |
| Many features, want automation | ğŸ¯ LASSO | Handles high dimensionality |
| Want to explore regularization | ğŸ¯ LASSO | Interactive Alpha control |
| Need to explain removals | ğŸ”™ Backward | Clear statistical justification |
| Want performance-focused selection | ğŸ”œ Forward | RÂ² directly measures improvement |

---

## ğŸ› ï¸ Tech Stack

<div align="center">

| Layer | Technology | Version | Purpose |
|:-----:|:----------:|:-------:|:--------|
| **ğŸ–¥ï¸ Frontend** | Streamlit | 1.28+ | Interactive web interface |
| **ğŸ Runtime** | Python | 3.10+ | Core programming language |
| **ğŸ“Š Data** | Pandas | 2.0+ | DataFrames & manipulation |
| **ğŸ”¢ Numerical** | NumPy | 1.24+ | Array operations |
| **ğŸ¤– ML Engine** | Scikit-Learn | 1.3+ | Models, CV, Grid Search, **Lasso** |
| **ğŸ“ˆ Statistics** | Statsmodels | 0.14+ | OLS, P-Values |
| **ğŸ“‰ Visualization** | Plotly | 5.18+ | Interactive charts |

</div>

### Triple-Library Feature Selection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FEATURE SELECTION: COMPLETE TOOLKIT                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                         â”‚   FEATURE SELECTION     â”‚                             â”‚
â”‚                         â”‚        SUITE            â”‚                             â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                     â”‚                                           â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚                      â”‚                      â”‚                    â”‚
â”‚              â–¼                      â–¼                      â–¼                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚    â”‚  ğŸ”™ BACKWARD    â”‚    â”‚  ğŸ”œ FORWARD     â”‚    â”‚  ğŸ¯ LASSO       â”‚            â”‚
â”‚    â”‚  ELIMINATION    â”‚    â”‚  SELECTION      â”‚    â”‚  (L1)           â”‚            â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚             â”‚                      â”‚                      â”‚                     â”‚
â”‚             â–¼                      â–¼                      â–¼                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚    â”‚  STATSMODELS    â”‚    â”‚  SCIKIT-LEARN   â”‚    â”‚  SCIKIT-LEARN   â”‚            â”‚
â”‚    â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚            â”‚
â”‚    â”‚  sm.OLS()       â”‚    â”‚  LinearReg()    â”‚    â”‚  Lasso()        â”‚            â”‚
â”‚    â”‚  .pvalues       â”‚    â”‚  r2_score()     â”‚    â”‚  .coef_         â”‚            â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                                 â”‚
â”‚    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•      â”‚
â”‚                                                                                 â”‚
â”‚    THREE LIBRARIES, THREE APPROACHES, ONE GOAL:                                 â”‚
â”‚    Identify the minimal set of features that explain the data.                  â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¥ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Git (for cloning)

### Step 1: Clone the Repository

```bash
git clone https://github.com/yourusername/ml-workbench.git
cd ml-workbench
```

### Step 2: Create Virtual Environment

```bash
# Create environment
python -m venv venv

# Activate (Linux/macOS)
source venv/bin/activate

# Activate (Windows)
.\venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### requirements.txt (v3.6)

```
streamlit>=1.28.0
scikit-learn>=1.3.0       # LinearRegression, Lasso, CV, GridSearch
statsmodels>=0.14.0       # OLS with P-Values
pandas>=2.0.0
numpy>=1.24.0
plotly>=5.18.0
matplotlib>=3.7.0
```

### Step 4: Verify Installation

```bash
python -c "
import streamlit
import sklearn
from sklearn.linear_model import Lasso
import statsmodels
import plotly

print('âœ… All dependencies installed!')
print(f'   Scikit-Learn: {sklearn.__version__}')
print(f'   - Lasso: Available âœ“')
print(f'   Statsmodels: {statsmodels.__version__}')
"
```

### Step 5: Launch the Application

```bash
streamlit run Home.py
```

Navigate to `http://localhost:8501` in your browser.

---

## ğŸ“– User Guide

### Using the Complete Feature Selection Suite

#### ğŸ”™ Tab 1: Backward Elimination

1. Click **ğŸ”™ Backward Elimination** tab
2. Observe the synthetic dataset with mixed features
3. Click **"Run Backward Elimination"**
4. Watch the Elimination Log as features are removed
5. Review the P-Value chart for surviving features

#### ğŸ”œ Tab 2: Forward Selection

1. Click **ğŸ”œ Forward Selection** tab
2. Click **"Run Forward Selection"**
3. Watch the RÂ² Growth Chart build step-by-step
4. Identify steep jumps (real signals) vs flat lines (noise)

#### ğŸ¯ Tab 3: LASSO (NEW!)

1. Click **ğŸ¯ LASSO** tab
2. **Adjust the Alpha slider** (start low, increase gradually)
3. **Watch the Coefficient Bar Chart update in real-time**
4. Observe noise features turn **RED** as they hit **0.00**
5. Note which features maintain their coefficients (real signals)

### Interpreting LASSO Results

| Visual Cue | Meaning |
|------------|---------|
| ğŸŸ© **Green bar** | Active feature (coefficient â‰  0) |
| ğŸŸ¥ **Red bar** | Eliminated feature (coefficient = 0.00) |
| **Tall bar** | Strong influence on prediction |
| **Short bar** | Weak influence (may shrink to 0 at higher Î±) |

### Recommended Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RECOMMENDED WORKFLOW                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  1. START with LASSO (Tab 3)                                                    â”‚
â”‚     â€¢ Quick overview of feature importance                                      â”‚
â”‚     â€¢ Slide Alpha to see shrinkage behavior                                     â”‚
â”‚                                                                                 â”‚
â”‚  2. VALIDATE with BACKWARD (Tab 1)                                              â”‚
â”‚     â€¢ Get statistical significance (P-Values)                                   â”‚
â”‚     â€¢ Confirm LASSO eliminations are statistically justified                    â”‚
â”‚                                                                                 â”‚
â”‚  3. VERIFY with FORWARD (Tab 2)                                                 â”‚
â”‚     â€¢ See incremental RÂ² contributions                                          â”‚
â”‚     â€¢ Confirm selected features actually improve model                          â”‚
â”‚                                                                                 â”‚
â”‚  4. COMPARE all three results                                                   â”‚
â”‚     â€¢ Agreement = High confidence in selection                                  â”‚
â”‚     â€¢ Disagreement = Investigate edge-case features                             â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ Disclaimer

<div align="center">

---

**ğŸ“š EDUCATIONAL USE ONLY**

---

</div>

This application is developed **exclusively for educational and demonstration purposes**.

- **Not for Production**: Results should not guide real-world decisions
- **Synthetic Data Only**: All datasets are algorithmically generated
- **No Warranty**: Software provided "as is"
- **Learning Tool**: Designed to build intuition, not replace professional analysis

---

## ğŸ‘¨â€ğŸ’» Author

<div align="center">

### **Waqar Salim**

*Master's Student & IT Professional*

---

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/yourprofile)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-181717?style=for-the-badge&logo=github)](https://github.com/yourusername)

---

### Version History

| Version | Codename | Modules | Key Addition |
|---------|----------|:-------:|--------------|
| v3.1 | Visual Basics | 4 | Core algorithms |
| v3.2 | Reliability Engineering | 5 | Cross-Validation |
| v3.3 | Automation Update | 6 | Grid Search |
| v3.4 | Feature Engineering | 7 | Backward Elimination |
| v3.5 | Selection Suite | 7 | + Forward Selection |
| **v3.6** | **Complete Suite** | **7** | **+ LASSO (L1)** |

---

**Built with ğŸ”™ elimination, ğŸ”œ selection, ğŸ¯ regularization, and â˜• persistence**

*The Machine Learning Workbench v3.6 â€” Three Paths to Feature Enlightenment*

---

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                               â•‘
â•‘   "Remove the garbage. Recruit the talent. Shrink the noise.                  â•‘
â•‘    Three philosophies, one truth: Simplicity is the ultimate sophistication." â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

![Footer](https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12,9,5,2&height=100&section=footer)

</div>
