<div align="center">

# ğŸ§  The Machine Learning Workbench

### **Version 3.2 â€” Reliability Engineering Edition**

*An Interactive Educational Platform for Visualizing ML Concepts & Model Validation*

---

![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.3+-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Version](https://img.shields.io/badge/Version-3.2-success?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

<br>

[**Features**](#-key-features) Â· [**Modules**](#-module-breakdown) Â· [**Installation**](#-installation) Â· [**User Guide**](#-user-guide)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Module Breakdown](#-module-breakdown)
- [Tech Stack](#-tech-stack)
- [Installation](#-installation)
- [User Guide](#-user-guide)
- [Disclaimer](#-disclaimer)
- [Author](#-author)

---

## ğŸš€ Overview

**The Machine Learning Workbench v3.2** introduces a pivotal shift toward **Reliability Engineering** â€” the discipline of ensuring ML models perform consistently, not just impressively on a single test.

This release addresses a critical blind spot in ML education: the dangerous reliance on single train-test splits. A model that scores 95% accuracy on one random split might score 78% on another. Without proper validation, you're flying blind.

### What's New in v3.2

| Release Focus | Description |
|---------------|-------------|
| ğŸ¯ **Reliability Engineering** | Shift from "does it work?" to "does it work *consistently*?" |
| ğŸ”¬ **Cross-Validation Lab** | New module for K-Fold CV experimentation (K=2 to K=10) |
| ğŸ“Š **Variance Visualization** | See model stability across multiple data splits |
| ğŸ“ˆ **Extended Metrics Suite** | F1-Score, Precision, Recall for classification; RÂ²/MSE for regression |

> **Core Philosophy:** A trustworthy model isn't one that performs well once â€” it's one that performs well *repeatedly*.

---

## âœ¨ Key Features

### âš”ï¸ Model Showdown

Compare **Linear vs. Non-Linear** algorithms head-to-head under identical conditions.

- **Side-by-Side Visualization** â€” Watch how Linear Regression and Decision Trees interpret the same data differently
- **Unified Test Sets** â€” Fair comparison on identical synthetic datasets
- **Performance Delta** â€” Instantly see which approach wins and by how much

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LINEAR REGRESSION  â”‚ VS  â”‚   DECISION TREE     â”‚
â”‚    RÂ² = 0.72        â”‚     â”‚    RÂ² = 0.89        â”‚
â”‚    [Linear Fit]     â”‚     â”‚  [Step Boundaries]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ”¬ Cross-Validation Lab (New in v3.2)

The flagship addition â€” a dedicated environment for understanding **K-Fold Cross-Validation**.

| Parameter | Range | Purpose |
|-----------|-------|---------|
| **K (Folds)** | 2â€“10 | Number of validation splits |
| **Model Type** | Classification / Regression | Task selection |
| **Metrics** | Accuracy, F1, RÂ², MSE | Performance measurement |

**What You'll Learn:**
- Why single splits are unreliable
- How averaging across folds produces robust estimates
- The bias-variance tradeoff in validation strategy

---

### ğŸ“ˆ Advanced Metrics Dashboard

Go beyond accuracy with a comprehensive metrics suite:

| Task | Metrics Available |
|------|-------------------|
| **Classification** | Accuracy, F1-Score, Precision, Recall |
| **Regression** | RÂ² Score, Mean Squared Error (MSE) |

Each metric is displayed per-fold, enabling granular analysis of model consistency.

---

## ğŸ“¦ Module Breakdown

The Workbench is organized into focused learning modules:

| Module | Name | Focus Area |
|--------|------|------------|
| A | Linear Regression | Continuous value prediction |
| B | Logistic Regression | Binary classification |
| C | Decision Trees | Non-linear boundaries |
| D | Model Showdown | Algorithm comparison |
| **E** | **Cross-Validation Lab** | **Reliability Engineering** |

---

### ğŸ”¬ Module E: Cross-Validation Lab

<div align="center">

**The Antidote to Overfitting Blindness**

</div>

#### The Problem: Single-Split Risk

When you evaluate a model on a single train-test split, you're gambling:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SINGLE SPLIT DANGER                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚   Split A:  Accuracy = 94%  â† "Great model!"               â”‚
â”‚   Split B:  Accuracy = 81%  â† "Wait, what?"                â”‚
â”‚   Split C:  Accuracy = 88%  â† "Which one is real?"         â”‚
â”‚                                                            â”‚
â”‚   Reality: Your model's TRUE performance is uncertain.     â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

A single evaluation is a **sample of one** â€” statistically meaningless for reliability assessment.

#### The Solution: K-Fold Cross-Validation

K-Fold CV systematically rotates through multiple train-test configurations:

```
K=5 FOLD CROSS-VALIDATION

â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ F1  â”‚ F2  â”‚ F3  â”‚ F4  â”‚ F5  â”‚   Fold 1: Test on F1, Train on F2-F5
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚TEST â”‚TRAINâ”‚TRAINâ”‚TRAINâ”‚TRAINâ”‚   â†’ Score: 0.87
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚TRAINâ”‚TEST â”‚TRAINâ”‚TRAINâ”‚TRAINâ”‚   Fold 2: Test on F2, Train on F1,F3-F5
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤   â†’ Score: 0.91
â”‚TRAINâ”‚TRAINâ”‚TEST â”‚TRAINâ”‚TRAINâ”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤   Fold 3: Test on F3...  â†’ Score: 0.84
â”‚TRAINâ”‚TRAINâ”‚TRAINâ”‚TEST â”‚TRAINâ”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤   Fold 4: Test on F4...  â†’ Score: 0.89
â”‚TRAINâ”‚TRAINâ”‚TRAINâ”‚TRAINâ”‚TEST â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜   Fold 5: Test on F5...  â†’ Score: 0.86

                                  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                  ROBUST AVERAGE: 0.874 Â± 0.025
```

**The CV Lab calculates:**
- **Mean Score**: The robust average across all K folds
- **Standard Deviation**: Measure of score variability
- **Per-Fold Breakdown**: Individual scores for each split

#### Supported Evaluation Modes

| Mode | Primary Metric | Secondary Metric |
|------|----------------|------------------|
| **Classification** | Accuracy | F1-Score |
| **Regression** | RÂ² Score | MSE (Neg.) |

The lab supports both paradigms, automatically adjusting the scoring strategy based on your selected task type.

---

## ğŸ› ï¸ Tech Stack

<div align="center">

| Component | Technology | Role |
|:---------:|:----------:|:-----|
| ğŸ | **Python 3.10+** | Core runtime environment |
| ğŸ¤– | **Scikit-Learn 1.3+** | ML algorithms & cross-validation |
| ğŸ–¥ï¸ | **Streamlit 1.28+** | Interactive web interface |
| ğŸ“Š | **Plotly 5.18+** | Dynamic visualizations |

</div>

---

## ğŸ“¥ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Git (for cloning)

### Step 1: Clone the Repository

```bash
git clone https://github.com/yourusername/ml-workbench.git
cd ml-workbench
```

### Step 2: Create Virtual Environment

```bash
# Create environment
python -m venv venv

# Activate (Linux/macOS)
source venv/bin/activate

# Activate (Windows)
.\venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### Step 4: Launch the Application

```bash
streamlit run Home.py
```

Navigate to `http://localhost:8501` in your browser.

---

## ğŸ“– User Guide

### ğŸ”¬ Using the Cross-Validation Lab

1. **Select Task Type** â€” Choose Classification or Regression
2. **Configure K** â€” Set the number of folds (2â€“10)
3. **Generate Data** â€” Create synthetic dataset with noise controls
4. **Run CV** â€” Execute cross-validation and observe results

---

### ğŸ“Š Interpreting the Variability Bar Chart

The CV Lab displays a bar chart showing **per-fold scores**. This visualization is the key to understanding model stability.

```
STABLE MODEL                    UNSTABLE MODEL
(Consistent Performance)        (Erratic Performance)

Score                           Score
  â”‚                               â”‚
1.0â”¤ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ   1.0â”¤ â–ˆâ–ˆâ–ˆâ–ˆ
   â”‚ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ      â”‚ â–ˆâ–ˆâ–ˆâ–ˆ      â–ˆâ–ˆâ–ˆâ–ˆ
0.8â”¤ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ   0.8â”¤ â–ˆâ–ˆâ–ˆâ–ˆ      â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ
   â”‚ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ      â”‚ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ
0.6â”¤ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ   0.6â”¤ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ
   â”‚ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ      â”‚ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ
0.4â”¤ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ   0.4â”¤ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ
   â”‚ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ      â”‚ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ
0.2â”¤ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ   0.2â”¤ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ
   â”‚ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ      â”‚ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ
  0â”¼â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€   0â”¼â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€
     F1   F2   F3   F4   F5          F1   F2   F3   F4   F5

   Mean: 0.85 | Std: 0.02          Mean: 0.72 | Std: 0.18
   âœ… TRUSTWORTHY                  âš ï¸ INVESTIGATE FURTHER
```

#### How to Read the Chart

| Pattern | Bars Appearance | Interpretation | Action |
|---------|-----------------|----------------|--------|
| **Even Heights** | All bars roughly equal | Model is stable across data splits | âœ… Confidence in deployment |
| **Uneven Heights** | Significant bar variation | Model is sensitive to data composition | âš ï¸ Consider regularization or more data |
| **One Outlier** | Single bar much lower/higher | Possible problematic fold or data issue | ğŸ” Investigate that specific split |
| **Declining Trend** | Bars decrease left to right | Potential data ordering issue | ğŸ”„ Shuffle data before CV |

> **Rule of Thumb:** If the standard deviation exceeds 10% of the mean, your model may be unreliable.

---

### â“ Why Does Regression MSE Appear Negative?

When viewing the CV results table for regression tasks, you'll notice **MSE values are negative**. This is not a bug â€” it's a Scikit-Learn convention.

#### The Technical Explanation

Scikit-Learn's `cross_val_score` function is designed as a **maximization framework**. All scoring metrics are oriented so that **higher is better**.

Since MSE is naturally a "lower is better" metric (you want *less* error), Scikit-Learn **negates it** to fit the maximization paradigm:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SCIKIT-LEARN SCORING CONVENTION             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Natural MSE:        0.25 (lower = better)                 â”‚
â”‚                          â†“                                  â”‚
â”‚   Scikit-Learn:      -0.25 (higher/less negative = better)  â”‚
â”‚                                                             â”‚
â”‚   Why? Unified optimization direction across all metrics.   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### How to Interpret

| Displayed Value | Actual MSE | Quality |
|-----------------|------------|---------|
| **-0.05** | 0.05 | Excellent (low error) |
| **-0.25** | 0.25 | Moderate |
| **-1.50** | 1.50 | Poor (high error) |

> **Remember:** For negative MSE, **closer to zero = better performance**.

#### Code Reference

```python
from sklearn.model_selection import cross_val_score

# Scikit-Learn returns negative MSE
scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')

# To get actual MSE values:
actual_mse = -scores
```

The Workbench displays the raw Scikit-Learn output to maintain consistency with industry-standard tooling.

---

## âš ï¸ Disclaimer

<div align="center">

---

**ğŸ“š EDUCATIONAL USE ONLY**

---

</div>

This application is developed **exclusively for educational and demonstration purposes**.

- **Not for Production**: Models and outputs should not be used for real-world decisions
- **Synthetic Data Only**: All datasets are algorithmically generated
- **No Warranty**: Software provided "as is" without guarantees
- **Learning Tool**: Designed to build intuition, not replace professional ML pipelines

The author assumes no liability for misuse or misinterpretation of results.

---

## ğŸ‘¨â€ğŸ’» Author

<div align="center">

### Waqar Salim**

---

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/yourprofile)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-181717?style=for-the-badge&logo=github)](https://github.com/yourusername)

---

**Built with ğŸ¯ precision and â˜• persistence**

*The Machine Learning Workbench v3.2 â€” Because Reliability Is Not Optional*

</div>
